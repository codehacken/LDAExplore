"The hemicube estimates of form factors are based on a finite set of sample directions. We obtain several optimal arrangements of sample directions, which minimize the variance of these estimates. They are based on changing the size or shape of the pixels or the shape of the hemicube, or using non-uniform pixel grids. The best reduces the variance by 43%. The variance calculation is based on the assumption that the errors in the estimate are caused by the projections of single polygon edges, and that the positions and orientations of these edges are random. This replaces the infinite dimensional space of possible environments by the two dimensional space of great circles on the unit sphere, making the numerical variance minimization possible"
"The paper proposes a scheme to perform volume rendering from compressed scalar data. Instead of decompressing the entire data set before rendering, blocks of data are decompressed as needed. Discrete cosine transform based compression technique is used to illustrate the method. The data is partitioned into overlapping blocks to permit local rendering and allow easy parallelization. Compression by factor of 20 to 30 produces rendering virtually indistinguishable from rendering using the original uncompressed data. Speedup is obtained by making use of spatial homogeneity detected in the transform domain. Rendering time using the proposed approach is less than that of direct rendering from the entire uncompressed data. The proposed method thus offers an attractive option to reduce storage, computation, and transmission overhead of otherwise huge data sets"
"The paper describes a new method for visualization and analysis of multivariate laser range data using complex valued non orthogonal Gabor wavelets (D. Gabor, 1946), principal component analysis and a topological mapping network. The initial data set that provides both shape and texture information is encoded in terms of both amplitude and phase of a complex valued 2D image function. A set of carefully designed oriented Gabor filters performs a decomposition of the data and allows for retrieving local shape and texture features. The feature vector obtained from this method is multidimensional and in order to evaluate similar data features, further subspace methods to transform the data onto visualizable attributes, such as R, G, B, have to be determined. For this purpose, a feature based visualization pipeline is proposed consisting of principal component analysis, normalization and a topological mapping network. This process finally renders a R,G,B subspace representation of the multidimensional feature vector. Our method is primarily applied to the visual analysis of features in human faces but is not restricted to that"
"So far, the problem of global illumination calculation has almost exclusively been approached from an algorithmic point of view. We propose an architectural approach to global illumination. The proposed rendering architecture Vision is derived from a model of the physical rendering process, which is subsequently mapped onto an object-oriented hierarchy of classes. This design is powerful and flexible enough to support and exploit a large body of existing illumination algorithms for the simulation of various aspects of the underlying physical model. Additionally, the Vision architecture offers a platform for developing new algorithms and for combining them to create new rendering solutions. We discuss both abstract design as well as implementation issues. In particular, we give a detailed description of the global lighting subsystem and show how algorithms for path tracing, bidirectional estimators, irradiance caching, hierarchical radiosity, wavelet radiosity, and wavelet radiance have been implemented within Vision"
"Networks are critical to modern society, and a thorough understanding of how they behave is crucial to their efficient operation. Fortunately, data on networks is plentiful; by visualizing this data, it is possible to greatly improve our understanding. Our focus is on visualizing the data associated with a network and not on simply visualizing the structure of the network itself. We begin with three static network displays; two of these use geographical relationships, while the third is a matrix arrangement that gives equal emphasis to all network links. Static displays can be swamped with large amounts of data; hence we introduce direct manipulation techniques that permit the graphs to continue to reveal relationships in the context of much more data. In effect, the static displays are parameterized so that interesting views may easily be discovered interactively. The software to carry out this network visualization is called SeeNet"
"Building on principles from prior work on procedural texture synthesis (K. Perlin, 1985), we are able to create remarkably lifelike, responsively animated characters in real time. Rhythmic and stochastic noise functions are used to define time varying parameters that drive computer generated puppets. Because we are conveying just the texturesof motion, we are able to avoid computation of dynamics and constraint solvers. The subjective impression of dynamics and other subtle influences on motion can be conveyed with great visual realism by properly tuned expressions containing pseudo random noise functions. For example, we can make a character appear to be dynamically balancing herself, to appear nervous, or to be gesturing in a particular way. Each move has an internal rhythm, and transitions between moves are temporally constrained so that impossible transitions are precluded. For example, if while the character is walking we specify a dance turn, the character will always step into the turn onto the correct weight bearing foot. An operator can make a character perform a properly connected sequence of actions, while conveying particular moods and attitudes, merely by pushing buttons at a high level. Potential uses of such high level textural approaches to computer graphic simulation include role playing games, simulated conferences, clip animation, graphical front ends for MUDs, and synthetic performances"
"Curves in space are difficult to perceive and analyze, especially when they form dense sets as in typical 3D flow and volume deformation applications. We propose a technique that exposes essential properties of space curves by attaching an appropriate moving coordinate frame to each point, reexpressing that moving frame as a unit quaternion, and supporting interaction with the resulting quaternion field. The original curves in 3-space are associated with piecewise continuous 4-vector quaternion fields, which map into new curves lying in the unit 3-sphere in 4-space. Since 4-space clusters of curves with similar moving frames occur independently of the curves' original proximity in 3-space, a powerful analysis tool results. We treat two separate moving-frame formalisms, the Frenet frame and the parallel-transport frame, and compare their properties. We describe several flexible approaches for interacting with and exploiting the properties of the 4D quaternion fields"
"Describes Obliq-3D, a high-level, fast-turnaround system for building 3D animations. Obliq-3D consists of an interpreted language that is embedded into a 3D animation library. This library is based on a few simple, yet powerful constructs that allow programmers to describe 3D scenes and animations of such scenes. By virtue of its interpretive nature, Obliq-3D provides a fast-turnaround environment. The combination of simplicity and fast turnaround allows programmers to construct nontrivial animations quickly and easily. The paper is divided into three major parts. The first part introduces the basic concepts of Obliq-3D, using a series of graduated examples. The second part shows how the system can be used to implement cone trees. The third part develops a complete animation of Dijkstra's (1959) shortest-path algorithm"
"Line integral convolution (LIC), introduced by Cabral and Leedom (1993) is a powerful technique for imaging and animating vector fields. We extend the LIC technique in three ways. Firstly the existing algorithm is limited to vector fields over a regular Cartesian grid. We extend the algorithm and the animation techniques possible with it to vector fields over curvilinear surfaces, such as those found in computational fluid dynamics simulations. Secondly we introduce a technique to visualize vector magnitude as well as vector direction, i.e., variable-speed flow animation. Thirdly we show how to modify LIC to visualize unsteady (time dependent) flows. Our implementation utilizes texture-mapping hardware to run in real time, which allows our algorithms to be included in interactive applications"
"Presents a method for visualizing unsteady flow by displaying its vortices. The vortices are identified by using a vorticity-predictor pressure-corrector scheme that follows vortex cores. The cross-sections of a vortex at each point along the core can be represented by a Fourier series. A vortex can be faithfully reconstructed from the series as a simple quadrilateral mesh, or its reconstruction can be enhanced to indicate helical motion. The mesh can reduce the representation of the flow features by a factor of 1000 or more compared with the volumetric dataset. With this amount of reduction, it is possible to implement an interactive system on a graphics workstation to permit a viewer to examine, in 3D, the evolution of the vortical structures in a complex, unsteady flow"
"This paper advocates the use of a group of renderers rather than any specific rendering method. We describe a bundle containing four alternative approaches to visualizing volume data. One new approach uses realistic volumetric gas rendering techniques to produce photo-realistic images and animations. The second uses ray casting that is based on a simpler illumination model and is mainly centered around a versatile new tool for the design of transfer functions. The third method employs a simple illumination model and rapid rendering mechanisms to provide efficient preview capabilities. The last one reduces data magnitude by displaying the most visible components and exploits rendering hardware to provide real time browsing capabilities. We show that each rendering tool provides a unique service and demonstrate the combined utility of our group of volume renderers in computational fluid dynamic (CFD) visualization. While one tool allows the explorer to render rapidly for navigation through the data, another tool allows one to emphasize data features (e.g., shock waves), and yet another tool allows one to realistically render the data. We believe that only through the deployment of groups of renderers will the scientist be well served and equipped to form numerous perspectives of the same dataset, each providing different insights into the data"
"Investigates the visualization of geometric algorithms. We discuss how limiting the domain makes it possible to create a system that enables others to use it easily. Knowledge about the domain can be very helpful in building a system which automates large parts of the user's task. A system can be designed to isolate the user from any concern about how graphics is done. The application need only specify what happens and need not be concerned with how to make it happen on the screen. We develop a conceptual model and a framework for experimenting with it. We also present a system, GASP (Geometric Animation System, Princeton), which implements this model. GASP allows quick generation of 3D geometric algorithm visualizations, even for highly complex algorithms. It also provides a visual debugging facility for geometric computing. We show the utility of GASP by presenting a variety of examples"
"In computational fluid dynamics, visualization is a frequently used tool for data evaluation, understanding of flow characteristics, and qualitative comparison with flow visualizations originating from experiments. Building on an existing visualization software system that allows for a careful selection of state-of-the-art visualization techniques and some extensions, it became possible to present various features of the data in a single image. The visualization shows vortex position and rotation as well as skin-friction lines, experimental oil-flow traces, shock-wave positions, and time surfaces. Animation provides a natural perception of flow in combination with an abstract representation of phenomena. By adding experimental flow visualization, a comparison between numerical simulation and wind-tunnel flow becomes possible up to a high level of detail. Since some of the underlying algorithms are not yet described in detail in the visualization literature, some experiences gained from the implementation are illustrated. The dedicated techniques which are illustrated in this paper address specific properties of vector quantities in the flow field, such as the velocity vector or the friction vector. Image complexity is reduced by employing complex visualization methods. Thus, the room is created which is necessary to study the interaction of various phenomena"
"This tutorial survey paper reviews several different models for light interaction with volume densities of absorbing, glowing, reflecting, and/or scattering material. They are, in order of increasing realism, absorption only, emission only, emission and absorption combined, single scattering of external illumination without shadows, single scattering with shadows, and multiple scattering. For each model the paper provides the physical assumptions, describes the applications for which it is appropriate, derives the differential or integral equations for light transport, presents calculation methods for solving them, and shows output images for a data set representing a cloud. Special attention is given to calculation methods for the multiple scattering model"
"Augmented reality entails the use of models and their associated renderings to supplement information in a real scene. In order for this information to be relevant or meaningful, the models must be positioned and displayed in such a way that they blend into the real world in terms of alignments, perspectives, illuminations, etc. For practical reasons the information necessary to obtain this realistic blending cannot be known a priori, and cannot be hard wired into a system. Instead a number of calibration procedures are necessary so that the location and parameters of each of the system components are known. We identify the calibration steps necessary to build a computer model of the real world and then, using the monitor based augmented reality system developed at ECRC (GRASP) as an example, we describe each of the calibration processes. These processes determine the internal parameters of our imaging devices (scan converter, frame grabber, and video camera), as well as the geometric transformations that relate all of the physical objects of the system to a known world coordinate system"
"A line art nonphotorealistic rendering scheme of scenes composed of freeform surfaces is presented. A freeform surface coverage is constructed using a set of isoparametric curves. The density of the isoparametric curves is set to be a function of the illumination of the surface determined using a simple shading model, or of regions of special importance such as silhouettes. The outcome is one way of achieving an aesthetic and attractive line art rendering that employs isoparametric curve based drawings that is suitable for printing publication"
"We present an efficient algorithm for dynamic adaptive color quantization of 24 bit image (video) sequences, important in multimedia applications. Besides producing hi fidelity 8 bit imagery, our algorithm runs with minimal computational cost and the generated colormaps are robust to small differences in consecutive images. Apart from the two standard color quantization tasks, colormap design and quantizer mapping, our algorithm includes colormap filling-an operation unique to dynamic color quantization. This task solves the problem of screen flicker, a serious problem in dynamic quantization of image sequences, resulting from rapid changes in display of colormaps. Our solution is based on two ideas: including in the current colormap a small set of color representatives from the previous image; assigning representatives to the colormap entries in an order that reduces the difference between contents of equal entries in consecutive colormaps. Our algorithm runs in near real time on medium range workstations"
"Particle path computation in unsteady 3D vector fields given in discrete, structured form (i.e., as a hexahedral curvilinear grid) requires the local approximation of the vector field and the path. Quadrilinear interpolation and Bernstein-Bezier polynomials are used for the local vector field and path approximation. The next point in a sequence of points on a particle path is computed using this local approximation. Bernstein-Bezier polynomials are primarily used in geometric modeling, and their properties allow direct computation of points on a particle path"
"The paper presents a new radiosity algorithm that allows the simultaneous computation of energy exchanges between surface elements, scattering volume distributions, and groups of surfaces, or object clusters. The new technique is based on a hierarchical formulation of the zonal method, and efficiently integrates volumes and surfaces. In particular no initial linking stage is needed, even for inhomogeneous volumes, thanks to the construction of a global spatial hierarchy. An analogy between object clusters and scattering volumes results in a powerful clustering radiosity algorithm, with no initial linking between surfaces and fast computation of average visibility information through a cluster. We show that the accurate distribution of the energy emitted or received at the cluster level can produce even better results than isotropic clustering at a marginal cost. The resulting algorithm is fast and, more importantly, truly progressive as it allows the quick calculation of approximate solutions with a smooth convergence towards very accurate simulations"
"Collision detection and response are important for interactive graphics applications such as vehicle simulators and virtual reality. Unfortunately, previous collision detection algorithms are too slow for interactive use. The paper presents a new algorithm for rigid or articulated objects that meets performance goals through a form of time critical computing. The algorithm supports progressive refinement, detecting collisions between successively tighter approximations to object surfaces as the application allows it more processing time. The algorithm uses simple four dimensional geometry to approximate motion, and hierarchies of spheres to approximate three dimensional surfaces at multiple resolutions. In a sample application, the algorithm allows interactive performance that is not possible with a good previous algorithm. In particular, the new algorithm provides acceptable accuracy while maintaining a steady and high frame rate, which in some cases improves on the previous algorithm's rate by more than two orders of magnitude"
"Conventional algorithms for scan-conversion of circles select one pixel in each iteration. Run-length slice circle algorithms have therefore been suggested. These algorithms determine a run of pixels in each iteration. The speed of scan-conversion is therefore increased due to I/O. A hybrid approach to the scan-conversion of circles is presented. The new approach combines the advantages of the two methods into a hybrid algorithm. Speedup is achieved in the hybrid algorithm not only due to the reduction in the number of I/O operations, but also due to a reduction in the number of arithmetic operations"
"Visualization and modeling of textile materials has already been investigated in detail in the computer graphics literature. Most of the work, however, concentrates on woven fabrics. We present a novel approach to the modeling and rendering of knitwear. After the topological specification of a knitting pattern a subdivision into basic elements is done. The yarn microstructure within basic elements is approximated by volume data sets. The repetitive structure of knitted fabrics allows an efficient rendering technique. Resulting images are given that demonstrate the feasibility of our approach"
"The development of virtual agents running within graphic environments which emulate real-life contexts may largely benefit from the use of visual specification by-example. To support this specification, the development system must be able to interpret the examples and cast their underlying rules into an internal representation language. This language must find a suitable trade-off among a number of contrasting requirements regarding expressiveness, automatic executability, and suitability to the automatic representation of rules deriving from the analysis of examples. A language is presented which attains this trade-off by combining together an operational and a declarative fragment to separately represent the autonomous execution of each individual agent and its interaction with the environment, respectively. While the declarative part permits to capture interaction rules emerging from specification examples, the operational part supports the automatic execution in the operation of the virtual environment. A system is presented which embeds this language within a visual shell to support a behavioral training in which the animation rules of virtual agents are defined through visual examples"
"Beginning with digitized volumetric data, we wish to rapidly and efficiently extract and represent surfaces defined as isosurfaces in the interpolated data. The Marching Cubes algorithm is a standard approach to this problem. We instead perform a decomposition of each 8-cell associated with a voxel into five tetrahedra. We guarantee the resulting surface representation to be closed and oriented, defined by a valid triangulation of the surface of the body, which in turn is presented as a collection of tetrahedra. The entire surface is wrapped by a collection of triangles, which form a graph structure, and where each triangle is contained within a single tetrahedron. The representation is similar to the homology theory that uses simplices embedded in a manifold to define a closed curve within each tetrahedron. We introduce data structures based upon a new encoding of the tetrahedra that are at least four times more compact than the standard data structures using vertices and triangles. For parallel computing and improved cache performance, the vertex information is stored local to the tetrahedra. We can distribute the vertices in such a way that no tetrahedron ever contains more than one vertex, We give methods to evaluate surface curvatures and principal directions at each vertex, whenever these quantities are defined. Finally, we outline a method for simplifying the surface, that is reducing the vertex count while preserving the geometry. We compare the characteristics of our methods with an 8-cell based method, and show results of surface extractions from CT-scans and MR-scans at full resolution"
"Ray tracing requires many ray-object intersection tests. A way of reducing the number of ray-object intersection tests is to subdivide the space occupied by objects into many nonoverlapping subregions, called voxels, and to construct an octree for the subdivided space. We propose the Octree-R, an octree-variant data structure for efficient ray tracing. The algorithm for constructing the Octree-R first estimates the number of ray-object intersection tests. Then, it partitions the space along the plane that minimizes the estimated number of ray-object intersection tests. We present the results of experiments for verifying the effectiveness of the Octree-R. In the experiment, the Octree-R provides a 4% to 47% performance gain over the conventional octree. The result shows the more skewed the object distribution (as is typical for real data), the more performance gain the Octree-R achieves"
"A high-performance algorithm for generating isosurfaces is presented. In our method, guides to searching for cells intersected by an isosurface are generated as a pre-process. These guides are two kinds of cell lists: an extrema graph, and sorted lists of boundary cells. In an extrema graph, extremum points are connected by arcs, and each arc has a list of cells through which it passes. At the same time, all boundary cells are sorted according to their minimum and maximum values, and two sorted lists are then generated. Isosurfaces are generated by visiting adjacent intersected cells in order. Here, the starting cells for this process are found by searching in an extrema graph and in sorted boundary cell lists. In this process, isosurfaces appear to propagate themselves. Our algorithm is efficient, since it visits only cells that are intersected by an isosurface and cells whose IDs are included in the guides. It is especially efficient when many isosurfaces are interactively generated in a huge volume. Some benchmark tests described in this paper show the efficiency of the algorithm"
